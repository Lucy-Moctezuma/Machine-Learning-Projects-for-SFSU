{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucy-Moctezuma/SFSU-CodeLab-Work-/blob/main/MARC%20Machine%20Learning%20Project/2_Yeast_Cells_with_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7yjTuAgXQJR"
      },
      "source": [
        "#**WELCOME to the coding portion for the Introduction to Deep Learning for Image Classification!**\n",
        "\n",
        "This notebook was created by Lucy Moctezuma Tan, Florentine van Nouhuijs, Lorena Benitez-Rivera (SFSU master students and CoDE lab members) and Pleuni Pennings (SFSU bio professor)\n",
        "\n",
        "Special Acknowledgement to Dr. Ilmi Yoon (SFSU CS professor) for providing the base code, to Dr. Mark Chan and his student lab members: Gabriela Alvarez-Azanedo and Adilene Rodriguez for sharing the lab images to use for the data analysis. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjRUQ6E9fzeG"
      },
      "source": [
        "#OBJECTIVE OF THIS EXERCISE:\n",
        "\n",
        "We are going to be working with 104 **yeast cells images** provided by Dr.Chan's lab and use a computer model to distinguish between two different ones: Wild Type (WT) and mutant (MT). \n",
        "- 61 images are already labeled and will be used as training images\n",
        "- 20 images are used for validation during the training process \n",
        "- 23 remaining images used for testing our model's performance.\n",
        "\n",
        "Below is an example for the two different types of yeast cells:\n",
        "\n",
        "![WT_vs_Mutant.png](https://drive.google.com/uc?export=view&id=1clVtBYMqxCIoE31uGmYnm5k74p3WZxoT)\n",
        "\n",
        "### Do they look similiar to you? let's see if the computer can determine that!\n",
        "\n",
        "**The Objective** of this workshop 2 is to use a **Deep Learning** model to predict which cells from the 23 test images are from the WT yeast cells, and which ones are the Mutant yeast cells.\n",
        "\n",
        "- ***Wild Type Cells:*** Mother cell transmits normal amount of vacuoles (green colored) to daughter cell.\n",
        "- ***Mutant Cells:*** Mother cell does not transmit normal amount of vacuoles (green colored) to daughter cell.\n",
        "\n",
        "In order to teach our model how to distinguish these cells, we are using images that had already been labeled by students from Mark's lab to train the model, and a technique called **Transfer Learning**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8EmKrEWkJJU"
      },
      "source": [
        "# DEEP LEARNING REVIEW:\n",
        "\n",
        "**Deep Learning**  is a method within Machine Learning (ML) in which the computer learns to accomplish a task through trial and error by analyzing training samples. Another common term for deep learning is **Artificial Neural Networks**.\n",
        "\n",
        "**Deep Learning** or **Artificial Neural Networks** were initially inspired by how neurons are organized and signal to each other in the brain.  \n",
        "\n",
        "\n",
        "**Artificial Neural Networks (ANN)** can be pictured as a series of stacked layers, and each layer is composed of different amounts of ***nodes***. All Neural networks are composed of an **input layer**, **hidden layers** and **output layer**. There are many types of ANN but all of them share the following features: \n",
        "\n",
        "![neuralnet.png](https://drive.google.com/uc?export=view&id=1UdEGkblSb3X__Y7ez6R1hJOQ4czP9RHC)\n",
        "\n",
        "**Image sources**: \n",
        "\n",
        "**Human Neural Networks**: https://upload.wikimedia.org/wikipedia/commons/5/5b/Cajal_cortex_drawings.png)\n",
        "\n",
        "**Artificial Neural Networks**: https://upload.wikimedia.org/wikipedia/commons/d/d2/Neural_network_explain.png\n",
        "\n",
        "### PARTS OF AN ARTIFICIAL NEURAL NETWORK\n",
        "\n",
        "**1) Input layer:** is the layer that we use to feed our initial data. These can be datatables, text, images, etc.\n",
        "\n",
        "**2) Hidden layers:** are the ones that will further process the information they receive from the input layer. In the example above we have 2 hidden layers but the amount of layers can vary.\n",
        "\n",
        "**3) Output layer:** is the final layer where we get our predictions.\n",
        "\n",
        "**4) Nodes:** are the the components of each layer and it represents a center where computation and mathematical equations determine what information is passed to the next layer. Nodes are connected to the following layer differently.\n",
        "\n",
        "**5) Weights:** are values that are meant to show the strenght of the relationship between each node. The general idea is that a neural network starts with a random set of weights and then during training, the weights get updated in a trial and error fashion until it finds the best combination of weights that will yield the highest performing model.  \n",
        "**Notice that in the image above, every black arrow has its own weight**\n",
        "\n",
        "You can find more information in the link:  [Neural Networks by IBM](https://www.ibm.com/cloud/learn/neural-networks#toc-how-do-neu-vMq6OP-P)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# TRANSFER LEARNING AND CONVOLUTIONAL NEURAL NETWORKS:\n",
        "\n",
        "This notebook will use a technique called **TRANSFER LEARNING** and a particular type of Artificial Neural Network, the **CONVOLUTIONAL NEURAL NETWORK(CNN)** , \n",
        "\n",
        "**- TRANSFER LEARNING** is using a pretrained neural network instead of creating and training your own from scratch. The reason machine learning practionists use this method is because CNNs are notorious for requiring a lot of images to train, and since we are using relatively few data, it is best to use an existing model that has been trained in millions of images already by companies.\n",
        "\n",
        "**Keras** is a python package that specializes in creating Artificial Neural Networks.  Here is a list of other pre-trained models in Keras : [Keras - Pretrained models](https://keras.io/api/applications/)\n",
        "\n",
        "**- CONVOLUTIONAL NEURAL NETWORKS (CNN)** , is a common type of ANN model used for image classification. The model looks at different local areas in the image and the hidden layers work together to extract specific image patterns, that will ultimately help our model classify our yeast cell.\n",
        "\n",
        "The Pre-trained Convolutional NeuralNetwork we will be using is the one called **VGG16.**"
      ],
      "metadata": {
        "id": "CSvhoylgQu4g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqUh5BwmE5wC"
      },
      "source": [
        "## **Step 1) Configuring Virtual Interpreter and Uploading image files from Github.**\n",
        "\n",
        "**A)** The Colab environment runs code cells on a virtual cloud computer owned by Google. To ensure that the code is executed efficiently, Graphics Processing Unit (GPU) must be enabled:\n",
        "\n",
        "* Navigate to 'Runtime' > 'Change Runtime Type'\n",
        "* Set 'Hardware Accelerator' to 'GPU'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzPtXad8IG_a"
      },
      "outputs": [],
      "source": [
        "#This code shows you the name of the GPU that was assigned to you\n",
        "!nvidia-smi --list-gpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rx2IjwUTSLF"
      },
      "source": [
        "**B)** Connect your Colab Notebook to your personal Drive so that there is a place to download your images to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFlBofTm951U"
      },
      "outputs": [],
      "source": [
        "#Mounting Google Drive into Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy-hNZXST0U6"
      },
      "source": [
        "**C)** Importing a package that allows you to connect to Github and download the images to your own Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wxAhkWSQVpR"
      },
      "outputs": [],
      "source": [
        "# This installs a package needed so that images are downloaded from github\n",
        "!pip install GitPython\n",
        "from git import Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROPcDrmCxH7h"
      },
      "outputs": [],
      "source": [
        "#Copying Github Repo folder structure into your Drive\n",
        "%cd /content/drive/MyDrive\n",
        "!git clone https://github.com/MarcMachineLearning/Introduction-to-Deep-Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCNLaLy0XbPI"
      },
      "source": [
        "## **Step 2) Importing needed packages to be able to run our neural network and creating a seed**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEGX5VIXpwL3"
      },
      "source": [
        "**A)** Importing all the packages needed to run our code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmv-ZBLaG_rc"
      },
      "outputs": [],
      "source": [
        "# imports packages to handle the math and data \n",
        "import numpy as np\n",
        "import random as random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMRJ3cozbUse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530dd5ad-e904-43a5-9985-96a76e6b3eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "# imports functions from tensorflow and keras that allow the CNN to be loaded, run and modified\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import keras as keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vv9UolviZ51"
      },
      "outputs": [],
      "source": [
        "# imports that will allow us to visualize and evaluate our model\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovRlm_S7n_Th"
      },
      "outputs": [],
      "source": [
        "#imports that let the notebook navigate the files in the drive\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVV2oF8JqZ62"
      },
      "source": [
        "**B)** Creating a function that will allow us to set a seed for our results.\n",
        "A **seed** is basically a set of predetermined numbers that are supposed to imitate randomness. A seed was set so that the results are reproducible and we can all look at the same results.\n",
        "\n",
        "**NOTE:** Usually people do not need to set up seeds for their Neural Networks but for educational purposes we will."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIOElm25qWXt"
      },
      "outputs": [],
      "source": [
        "def random_seed_GPU(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "#fix seed\n",
        "random_seed_GPU(45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBciMKeHJsO-"
      },
      "source": [
        "## **Step 3) Loading VGG16 Pre-trained CNN**\n",
        "\n",
        "**VGG16** is a pre-trained CNN that has been already trained with millions of images, so it has learned important ways to distinguish basic image components such as edges, horizontal vs vertical lines or background versus foreground, etc. This information can be used to also recognize our yeast cells.\n",
        "\n",
        "![VVG16.png](https://drive.google.com/uc?export=view&id=1c0_Oaq3rRTHwl6KvdztsEk7RpH2rf871)\n",
        "\n",
        "### PARTS OF VGG16\n",
        "\n",
        "#### **1) Input layer** \n",
        "This layer consists of the images generated by our Image Generator, each image will be passed first through the input layer.\n",
        "\n",
        "#### **2) Hidden layers** \n",
        "VGG16 has hidden layers that are composed of Feature learning layers **(A)** and Classification layers **(B)**.\n",
        "\n",
        "**A) Feature learning layers**\n",
        "You can think of these layers as learning the features of the images such as borders, vertical vs horizontal lines, etc. As you can see in the image, they are grouped in blocks called **convolutional blocks**. VGG16 has 5 blocks\n",
        "  - **Convolutional layers**: function basically as different filters for the image, such as detecting edges, darker or lighter spots, etc. The end product of a convolution layer is called a **Feature Map**\n",
        "  - **Maxpooling layers**: are layers that reduce the dimensions of the filtered images, this is important because every image that goes through our network will go through several filters and this could make an image have too much information. Maxpooling tries to preserve the most important features of the image while also making it easier to process.\n",
        "\n",
        "![Convo_Max.png](https://drive.google.com/uc?export=view&id=1gYJQBAbLsNya9HYLve0epR4hGydU7QAz)\n",
        "\n",
        "**Image source**:https://picryl.com/media/the-golden-gate-bridge-650ae8\n",
        "\n",
        "**B) Classification layers**\n",
        "- **Flatten layer**: This layer is the one that takes all the filtered images created in the last convolutional block. the images are represented as 2D arrays and turns them into 1D vectors. This step is important since it is necessary to feed it into the Dense layers.\n",
        "\n",
        "![2d into 1d.png](https://drive.google.com/uc?export=view&id=1SaHoqsniGDI3tpgDO3QlicfsLogbDgwX)\n",
        "\n",
        "- **Dense layers**: are also called fully connected layers because each neuron is connected to every other neuron from the next layer. VGG16 has 2 that start to perform the classification process. \n",
        "\n",
        "#### **4) Output layer**\n",
        "VGG16 contains a final output layer with the predicted classes. This final dense layer contains 1000 channels because it was designed to classify 1000 classes of images, the output shows the probabilities of belonging to a particular class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04kj8GF3HS1j"
      },
      "outputs": [],
      "source": [
        "# load a preset model from keras that has been trained by tons of images and check a summary of it\n",
        "vgg16_model = tf.keras.applications.VGG16()\n",
        "vgg16_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcLPu2Bpgkk0"
      },
      "source": [
        "## **Step 4) Loading Training and Validation Data to look at the Images used for Training**\n",
        "\n",
        "We devided the images into training and validation into different folders, please note that both are labeled images.\n",
        "\n",
        "  **A) Training:** 61 Images that will be used to train only the last layer of our CNN, that is the output layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNcGnG5nf3dI"
      },
      "outputs": [],
      "source": [
        "# Load data folders with images from the Drive\n",
        "train_path = '/content/drive/MyDrive/Introduction-to-Deep-Learning/Training'\n",
        "image_size = (224, 224)\n",
        "classes = os.listdir(train_path)\n",
        "print(\"Training:\")\n",
        "train_batches = ImageDataGenerator() \\\n",
        "                .flow_from_directory(train_path,\n",
        "                                    image_size,\n",
        "                                    classes=classes,\n",
        "                                    class_mode = \"categorical\",\n",
        "                                    batch_size=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **B) Validation:** 20 Images that are labeled already and that will be used to validate during the training in order to check how the CNN is performing while training. It is performed however many times is specified in the \"validation steps\" "
      ],
      "metadata": {
        "id": "sLka4pAgqHLz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vFLOcjffjHr"
      },
      "outputs": [],
      "source": [
        "valid_path = '/content/drive/MyDrive/Introduction-to-Deep-Learning/Validation'\n",
        "\n",
        "print(\"Validation:\")\n",
        "valid_batches = ImageDataGenerator() \\\n",
        "                .flow_from_directory(valid_path,\n",
        "                                       image_size,\n",
        "                                       classes=classes,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       batch_size=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWh2ZprvyP6h"
      },
      "source": [
        "**C)** Let's visualize some of the images we will be training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCmQH0-9HPx7"
      },
      "outputs": [],
      "source": [
        "# function that plots images with labels\n",
        "def plots(ims, figsize=(20,20), rows=1, interp=False, titles=None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            title_list = []\n",
        "            for t in titles:\n",
        "                for element in t:\n",
        "                    if element == 1:\n",
        "                      index = list(t).index(element)\n",
        "                      if index in list(train_batches.class_indices.values()):\n",
        "                            label = list(train_batches.class_indices.keys())[index]\n",
        "                            title_list.append(label)\n",
        "        sp.set_title(title_list[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "\n",
        "imgs, train_labels = next(train_batches)\n",
        "plots(imgs[0:5], titles=train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8rh0yqVKXMl"
      },
      "source": [
        "## **Step 5) Fine Tunning VGG16 for our dataset**\n",
        "\n",
        "**Fine Tunning (Adapting)** Means that we need to change the pre-trained network VGG16 into one that can work with our data. \n",
        "\n",
        "**A)** The code below copies all the layers and weights of vgg16 and freezes them and then it adds the last layer, the only layer that is trainable. The only layer we are interested in changing is the last one. The original allows us to classify about 1000 classes but we only have two classes. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7fJH08vCz_P"
      },
      "outputs": [],
      "source": [
        "# make modifications to the last layer only and check a summary of it\n",
        "\n",
        "model = Sequential()\n",
        "for layer in vgg16_model.layers[:-1]:  \n",
        "    model.add(layer)\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "model.add(Dense(len(classes), kernel_initializer=keras.initializers.glorot_uniform(seed=45) ,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9ro0v4kL8g5"
      },
      "source": [
        "## **Step 6) Compiling the model and Training our Data** \n",
        "\n",
        "**A)** Compiling allows us to set different parameters such as how fast we want it to learn or how we want our model to calculate it's performace.\n",
        "\n",
        "- **Learning rate**: is a value between 0 and 1, that determines basically how fast our model will try to learn. The higher the learning rate, the less number of epochs (training cycles) is required. This is the most important parameter to tune in a Neural Network. Too large and it will converge too quickly and provide a suboptimal result, too small and it will get stuck. \n",
        "\n",
        "- **Loss**: There are many kinds of loss functions and it depends on what you are trying to predict, for example ours is *categorical crossentropy*. It is essentially a way to measure how well your model fits your data. The lower the better.\n",
        "\n",
        "- **Metrics**: allows us to choose how we want to evaluate our model, for example i chose *accuracy*. This measures the percentage of correct predictions over the total predictions made by our model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzJyijpRJQ4w"
      },
      "outputs": [],
      "source": [
        "# compile model to determine learning rate, loss function and metrics\n",
        "model.compile(Adam(learning_rate=.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ufxcwdJ-7A"
      },
      "source": [
        "We are going to use now the 61 training images and the 20 validation images together for the training. \n",
        "\n",
        "**Note:** We have also set a seed during training so that the images are fed to the model in the same order, that way the training process is reproducible.\n",
        "\n",
        "**B)** In order to do our training we can specify the following parameters: \n",
        "\n",
        "- **Epoch:** is one cycle of training, meaning our entire training data goes through all the layers of our neural network forwards and then backwards.\n",
        "\n",
        "- **Steps per Epoch:** Each epoch is devided into steps that depend on the  number of images per training batch. The first step starts with a set of random weights, once the first batch of training data reaches the end of the network, it then goes backwards upgrading the weights. This phenomenon is called **Backpropagation**. \n",
        "\n",
        "> One step = 1 backpropagation.\n",
        "\n",
        "- **Validation Steps:** This is similar to Steps per epoch, except it is for the validation set of images. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVv4DEyJD-1D"
      },
      "outputs": [],
      "source": [
        "#fix seed\n",
        "random_seed_GPU(45)\n",
        "\n",
        "STEP_SIZE_TRAIN=train_batches.n//train_batches.batch_size\n",
        "STEP_SIZE_VALID=valid_batches.n//valid_batches.batch_size\n",
        "\n",
        "model.fit(train_batches,\n",
        "          steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "          validation_data=valid_batches,\n",
        "          validation_steps=STEP_SIZE_VALID,\n",
        "          epochs=10,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93w8DUFzMGYH"
      },
      "source": [
        "## **Step 7) Predicting labels for the Test Data**\n",
        "\n",
        "**Testing:** 23 Images that our CNN model has never seen will be loaded. Our model will then attempt to predict labels for the testing set. We will then compared our test images with the predictions made by our model to determine how good our model is.\n",
        "\n",
        "**A)** Loading our Testing Set of images\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VlxtRBSfmqu"
      },
      "outputs": [],
      "source": [
        "test_path = '/content/drive/MyDrive/Introduction-to-Deep-Learning/Testing'\n",
        "\n",
        "print(\"Testing:\")\n",
        "test_batches = ImageDataGenerator() \\\n",
        "                .flow_from_directory(test_path,\n",
        "                                     image_size,\n",
        "                                     classes=classes,\n",
        "                                     class_mode = \"categorical\",\n",
        "                                     batch_size=23, \n",
        "                                     shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKIMniLTZq2f"
      },
      "source": [
        "**B)** Making predictions for the Test Data\n",
        "\n",
        "Each prediction outputs a probability between 0 to 1 for each class. Whatever probability is the highest, is the one that ends up being as the predicted class.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSNd1kAiV-MC"
      },
      "outputs": [],
      "source": [
        "#Makes prediction with our models\n",
        "pred=model.predict(test_batches,\n",
        "steps=1,\n",
        "verbose=2)\n",
        "\n",
        "#Observe the probablilities predicted for each class \n",
        "pred = np.round(pred, 2)\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NosH_7SKakfZ"
      },
      "source": [
        "**C)** Lets Convert our predictions into the actual classes predicted by our model to make it easier to read the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98cFQycTB2AO"
      },
      "outputs": [],
      "source": [
        "#convert predictions into actual labels\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "labels = (train_batches.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "#observing the actual labels predicted\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DItc95Zdkzdi"
      },
      "source": [
        "## **Step 8) Observe how many predictions were correct using a Confusion Matrix**\n",
        "\n",
        "**Confusion Matrix**: is a chart that lets you observe the number of accurate predictions and mistakes made by the model.\n",
        "\n",
        "**A)** Loading Actual data labels to make our confusion matrix.\n",
        "\n",
        "**Actual Values** are the ones that are already labeled correctly in our test data by a human.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTzdB1KRGN7S"
      },
      "outputs": [],
      "source": [
        "# This line of code turns our Actual Data into a list of \"Mutant\" and \"WT\" list\n",
        "array = test_batches.classes\n",
        "actual_data= array.tolist()\n",
        "Actual = []\n",
        "for i in actual_data:\n",
        "  if i == 0:\n",
        "    i = \"Mutant\"\n",
        "    Actual.append(i)\n",
        "  elif i == 1:\n",
        "    i = \"WT\"\n",
        "    Actual.append(i)\n",
        "\n",
        "Actual   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPYYiTyalaqB"
      },
      "source": [
        "**B)** Let's take a look at our confusion matrix!\n",
        "\n",
        "**Predicted Values:** Are the ones that our model has made using our unlabelled test data.\n",
        "\n",
        "What the model predicted *correctly*:\n",
        "- **True WT**: Model predicted \"Wild Type\" and it was actually \"Wild Type\"\n",
        "- **True Mutant**: Model predicted \"Mutant\" and it was actually \"Mutant\"\n",
        "\n",
        "What the model predicted *wrong*:\n",
        "- **False WT**: Model predicted \"Wild Type\" but it was actually \"Mutant\"\n",
        "- **False Mutant**: Model predicted \"Mutant\" but it was actually \"Wild Type\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIL729h_80Wk"
      },
      "outputs": [],
      "source": [
        "#Create Confusion matrix for 2 classes\n",
        "cm = confusion_matrix(Actual, predictions)\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     index = ['Mutant','WT'], \n",
        "                     columns = ['Mutant','WT'])\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm_df, annot=True)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the Y axis of the **Confusion Matrix** you see the actual values, on the x axis you see the values that the model predicted. \n",
        "\n",
        "The model used 23 images for testing. From these images: \n",
        "- The model incorrectly predicted 2 Wild Types When the Actual category was Mutant (upper right corner). \n",
        "- The model incorrectly predicted 1 mutant when the Actual category was Wild Type (bottom left corner).\n",
        "- The model correctly predicted 10 mutants to be mutants (upper left corner).\n",
        "- The model correctly predicted 10 wildtypes to be Wild Type (bottom right corner).\n",
        "\n",
        "**C)** Let's take a look at the image it predicted incorrectly as a Wild Type"
      ],
      "metadata": {
        "id": "Yw30Jg3Q40wB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code allows you to see which image was predicted incorrectly\n",
        "test_batches.reset()\n",
        "test_imgs, test_labels = next(test_batches)\n",
        "test_labels = test_labels[:,0]\n",
        "pred_labels= np.round(pred[:,0])\n",
        "\n",
        "false_wt = np.where(np.logical_and(test_labels == 1, pred_labels == 0))\n",
        "imgs, labels = next(test_batches)\n",
        "plots(imgs[false_wt[0]], titles=labels)"
      ],
      "metadata": {
        "id": "qy12rQIw2Pac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_Ry2-Fyjezs"
      },
      "source": [
        "**C)** Evaluating our model will allow us to get concrete metrics of how our model performed. We can see how well we performed by looking at the following metrics:\n",
        "- **Accuracy**: metric showing us what percentage of the test data was predicted correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8LmiI3xJZXs"
      },
      "outputs": [],
      "source": [
        "#Evaluating the model using test batches\n",
        "test_acc = model.evaluate(test_batches, \n",
        "                          steps=1,\n",
        "                          verbose=1) \n",
        "print(test_acc[1]) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model got a 86.96% Accuracy. Woohooo!! The computer was able to distinguish Wild Type vs Mutant Yeast Cells!\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16cXtuethRuM8mlJd5qXusKjGaRgbpzEs\" width=400 lenght=400>\n",
        "\n",
        "### **We Hope you had Fun Doing this Deep Learning Workshop. As you can see it's not that hard!**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3ta1ejjpOyhK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}