{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhY9txHuVxk6CAAdq9tcja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucy-Moctezuma/SFSU-CodeLab-Work-/blob/main/E.%20Coli%20Machine%20Learning%20Project/5_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Learning**"
      ],
      "metadata": {
        "id": "4s_KUXfGSthq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1) Importing Packages needed**"
      ],
      "metadata": {
        "id": "fnpxHzYUUJ_M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDa820s0JSoJ"
      },
      "outputs": [],
      "source": [
        "# Data manipulation imports for ML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import packages for Neural Networks model\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Imports for model evaluation \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Imports for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Imports for file management\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2) Loading CSV file and creating dataframes for each antibiotic**"
      ],
      "metadata": {
        "id": "1MTk8vozVJqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **a) Loading CSV created from previous notebook**"
      ],
      "metadata": {
        "id": "QNuEJfKcVSLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads csv file as a dataframe\n",
        "filepath = '/content/drive/My Drive/EColi_ML_CSV_files/'\n",
        "\n",
        "# reads csv file as a dataframe\n",
        "All_Drugs_df = pd.read_csv(filepath+\"EColi_Merged_dfs.csv\", na_values=\"NaN\")\n",
        "All_Drugs_df"
      ],
      "metadata": {
        "id": "psqfFp_yVsmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **b) Changing \"R\" to 0 and \"S\" to 1  for Deep Learning Model**"
      ],
      "metadata": {
        "id": "Gnvbqq1Eduja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a list of antibiotic names\n",
        "drug_list = All_Drugs_df.iloc[:,1:13].columns\n",
        "drug_list\n",
        "\n",
        "# converts all S values into 0 for each antibiotic\n",
        "for drug in drug_list:\n",
        "  All_Drugs_df.loc[All_Drugs_df[drug] == \"S\", drug] = 1.0\n",
        "\n",
        "# converts all R values into 1 for each antibiotic\n",
        "for drug in drug_list:\n",
        "  All_Drugs_df.loc[All_Drugs_df[drug] == \"R\", drug] = 0.0\n",
        "\n",
        "# Checking at how S and R classes were recoded\n",
        "All_Drugs_df.head()"
      ],
      "metadata": {
        "id": "lLeCU30hD0Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **c) Creating dataframes for each drug**"
      ],
      "metadata": {
        "id": "7R5n7AplVk-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a function that makes dataframes for each antibiotic and dropping NaN values\n",
        "def makeDF(drug):\n",
        "  All_features = All_Drugs_df.iloc[:,13:].astype(float)\n",
        "  df_list = [All_Drugs_df[[\"Isolate\",drug]],All_features]\n",
        "  Drug_df = pd.concat(df_list, axis=1)\n",
        "  Drug_df = Drug_df.dropna()\n",
        "  return Drug_df\n"
      ],
      "metadata": {
        "id": "CL1DDOxXEXER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing function using as example the drug AMC\n",
        "AMX_df = makeDF(\"AMX\")\n",
        "\n",
        "# looking at the shape of AMC dataframe\n",
        "print(\"AMX dataframe shape: \", AMX_df.shape)\n",
        "\n",
        "# looking at the first 5 rows of this dataframe\n",
        "AMX_df.head()"
      ],
      "metadata": {
        "id": "Z8ilX07xpqLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3) Separating each Drug Dataframe into 4 sections : Training (features and labels) and Testing (features and labels)**"
      ],
      "metadata": {
        "id": "NMKzeaqPojso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **a) Creating Testing and Training datasets for each antibiotic drug**"
      ],
      "metadata": {
        "id": "B2BblFQkce6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating each dataframe into Labels and Features\n",
        "def Split_train_test(Drug_df,drug):\n",
        "  Train_test_dic = {}\n",
        "  labels = Drug_df[drug]\n",
        "  features = Drug_df.drop(columns=[drug])\n",
        "  features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42, stratify=labels)\n",
        "\n",
        "  Train_test_dic['labels_train'] = labels_train\n",
        "  Train_test_dic['features_train'] = features_train\n",
        "  Train_test_dic['labels_test'] = labels_test\n",
        "  Train_test_dic['features_test'] = features_test\n",
        "\n",
        "  return Train_test_dic"
      ],
      "metadata": {
        "id": "iP4HEW4qBO7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the function Split_train_test() for AMC example\n",
        "AMX_Train_test_dic = Split_train_test(AMX_df,\"AMX\")\n",
        "AMX_Train_test_dic[\"features_train\"].columns\n",
        "\n",
        "# checking the shape of each dataframe or series stored in the dictionary created for drug AMC\n",
        "print(\"AMX\")\n",
        "for k, df in AMX_Train_test_dic.items():\n",
        "  print(k, df.shape)\n",
        "\n",
        "# Checking how many samples are Resistant and how many Susceptible to AMC\n",
        "AMX_Train_test_dic[\"labels_train\"].value_counts()"
      ],
      "metadata": {
        "id": "43qPwvrrqCaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4) Creating different combination of features before training**"
      ],
      "metadata": {
        "id": "2IyqN506dQn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making a list of combinations of data sources we would like to test in our ML models\n",
        "combo_list = ['G', 'S', 'GY', 'SY', 'GS', 'GYS'] \n",
        "\n",
        "# making a function that creates different feature combinations of the predictor features\n",
        "def combo_feat(features_df, drug, combo):\n",
        "\n",
        "  # creating Year column filters for features_df\n",
        "  year_filter = [col for col in features_df if col.startswith(\"Year\")]\n",
        "  year_feat = features_df[year_filter]\n",
        "\n",
        "  # creating Population structure column filters for features_df\n",
        "  pop_str_filter = [col for col in features_df if col.startswith(\"cutoff\")]\n",
        "  pop_struc_feat = features_df[pop_str_filter]\n",
        "\n",
        "  # creating Gene precence column filters for features_df\n",
        "  gene_presc_filter = [col for col in features_df.columns if col not in pop_str_filter and col not in year_filter and col != \"Isolate\"]\n",
        "  gene_presc_feat = features_df[gene_presc_filter]  \n",
        "\n",
        "  if combo == 'G':\n",
        "    df_list = [features_df['Isolate'], gene_presc_feat]\n",
        "    G_feat_df = pd.concat(df_list, axis=1)\n",
        "    G_feat_df = scale(G_feat_df.drop(columns=['Isolate']))\n",
        "    return G_feat_df\n",
        "\n",
        "  if combo == 'S':\n",
        "    df_list = [features_df['Isolate'], pop_struc_feat]\n",
        "    S_feat_df = pd.concat(df_list, axis=1)\n",
        "    S_feat_df = scale(S_feat_df.drop(columns=['Isolate']))\n",
        "    return S_feat_df\n",
        "\n",
        "  if combo == 'GY':\n",
        "    df_list = [features_df['Isolate'], gene_presc_feat, year_feat]\n",
        "    GY_feat_df = pd.concat(df_list, axis=1)\n",
        "    GY_feat_df = scale(GY_feat_df.drop(columns=['Isolate']))\n",
        "    return GY_feat_df\n",
        "\n",
        "  if combo == 'SY':\n",
        "    df_list = [features_df['Isolate'], pop_struc_feat, year_feat]\n",
        "    SY_feat_df = pd.concat(df_list, axis=1)\n",
        "    SY_feat_df = scale(SY_feat_df.drop(columns=['Isolate']))\n",
        "    return SY_feat_df\n",
        "\n",
        "  if combo == 'GS':\n",
        "    df_list = [features_df['Isolate'], gene_presc_feat, pop_struc_feat]\n",
        "    GS_feat_df = pd.concat(df_list, axis=1)\n",
        "    GS_feat_df = scale(GS_feat_df.drop(columns=['Isolate']))\n",
        "    return GS_feat_df\n",
        "\n",
        "  if combo == 'GYS':\n",
        "    df_list = [features_df['Isolate'], gene_presc_feat, year_feat, pop_struc_feat]\n",
        "    GYS_feat_df = pd.concat(df_list, axis=1)\n",
        "    GYS_feat_df = scale(GYS_feat_df.drop(columns=['Isolate']))\n",
        "    return GYS_feat_df"
      ],
      "metadata": {
        "id": "JmzbwQBxlylk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing combo_feat() function created for training data\n",
        "AMX_GS_train_array = combo_feat(AMX_Train_test_dic['features_train'],\"AMX\",\"GS\")\n",
        "\n",
        "# Each list within the array represents a row\n",
        "print(AMX_GS_train_array)\n",
        "print(\"Number of rows: \",len(AMX_GS_train_array))"
      ],
      "metadata": {
        "id": "z6f4cke-qHxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5) Creating Deep Learning model and training it per feature combination**\n",
        "\n",
        "Below we can test changing the parameters to fine tune our results"
      ],
      "metadata": {
        "id": "ZVOKCEZNeHzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter values\n",
        "firstlayer = 200\n",
        "interlayer = 100\n",
        "dropout = 0.8\n",
        "numblayer = 2"
      ],
      "metadata": {
        "id": "MET6tCQ4O_Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating function to run Deep Learning and implementing it:"
      ],
      "metadata": {
        "id": "b-4ZZyH2ae7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating Deep Learning model function\n",
        "def run_DL(feat_train_df, lab_train, drug, combo, sum = True):\n",
        "  print(drug +\" Training combo: \"+ combo)\n",
        "  \n",
        "  # Reweighting classes due to imbalanced dataset\n",
        "  class_labels = np.unique(lab_train)\n",
        "  reweight = compute_class_weight(class_weight='balanced', classes=class_labels, y=lab_train)\n",
        "  print(reweight)\n",
        "  \n",
        "  # Constructing Deep Learning model\n",
        "  DL = Sequential()\n",
        "  DL.add(Dense(int(firstlayer),activation='relu', input_shape=(feat_train_df.shape[1],)))\n",
        "  DL.add(Dropout(dropout, input_shape=(feat_train_df.shape[1],)))\n",
        "  for i in range(1,int(numblayer)):\n",
        "      DL.add(Dense(int(interlayer),activation='relu'))\n",
        "      DL.add(Dropout(dropout))\n",
        "  DL.add(Dense(2, activation = 'softmax'))\n",
        "\n",
        "  # Additional parameters for training (Early stopping)\n",
        "  early_stopping_monitor= EarlyStopping(patience=50)\n",
        "\n",
        "  # Compiling model created\n",
        "  DL.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.0001) ,loss= 'binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  # Printing the model layers and parameters\n",
        "  if sum == True:\n",
        "    DL.summary()\n",
        "  \n",
        "  # Training with the neural network created\n",
        "  DL_history = DL.fit(feat_train_df, to_categorical(lab_train), validation_split = 0.2, callbacks= [early_stopping_monitor],epochs=10, batch_size=128, class_weight=dict(enumerate(reweight)))\n",
        "\n",
        "  return DL\n"
      ],
      "metadata": {
        "id": "QbEP2WYkWPxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing run_DL() for specific drug feature combination dataframe\n",
        "DL_AMX_GS_model = run_DL(AMX_GS_train_array, AMX_Train_test_dic['labels_train'],\"AMX\",\"GS\")\n",
        "DL_AMX_GS_model"
      ],
      "metadata": {
        "id": "kJgB0ELDqLVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6) Making predictions from Deep Learning model**"
      ],
      "metadata": {
        "id": "1px3jn-Djn77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzEGZrwHAZ3W"
      },
      "outputs": [],
      "source": [
        "# creating a function using the model created and trained and the feature combinations from testing data\n",
        "def predict(DL_combo_Model, features_test):\n",
        "  labels_pred = DL_combo_Model.predict(features_test)\n",
        "  labels_pred = np.argmax(labels_pred, axis=1)\n",
        "  return labels_pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing combo_feat() function created for testing data\n",
        "AMX_GS_test_array = combo_feat(AMX_Train_test_dic['features_test'],\"AMX\",\"GS\")\n",
        "\n",
        "# Each list within the array represents a row\n",
        "print(AMX_GS_test_array)\n",
        "print(\"Number of rows: \",len(AMX_GS_test_array))"
      ],
      "metadata": {
        "id": "cbzJt4FaqTIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of the predict() function using the feature combination \"GS\"\n",
        "AMX_GS_labels_pred = predict(DL_AMX_GS_model,AMX_GS_test_array)\n",
        "\n",
        "# observe how many predictions were made for each category \"R\"=0 and \"S\"=1\n",
        "print(\"Labels predicted: \")\n",
        "print(AMX_GS_labels_pred)"
      ],
      "metadata": {
        "id": "DIk2WxCzqTjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7) Evaluating our model using a confusion matrix and metrics**"
      ],
      "metadata": {
        "id": "5dox3JfFn5wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function that evaluates our model using our actual and predicted data\n",
        "def evaluate(DL_combo_model, features_test, labels_test, labels_pred, cf= True):\n",
        "  \n",
        "  labels_test = np.asfarray(labels_test,float)\n",
        "  score = DL_combo_model.evaluate(features_test, to_categorical(labels_test)) # only take accuracy\n",
        "  \n",
        "  labels = unique_labels(labels_test, labels_pred)\n",
        "  inp = precision_recall_fscore_support(labels_test, labels_pred, labels=labels, average=None) # get f1 scores\n",
        "  print(inp)\n",
        "  report = np.asarray(inp).ravel().tolist()\n",
        "  report= pd.DataFrame(report, index = ['PRC_R','PRC_S','RCL_R','RCL_S','FSc_R','FSc_S','Sc_R','Sc_S'])\n",
        "  report = report.transpose()\n",
        "  print(report)\n",
        "\n",
        "  if cf == True:\n",
        "    cm = confusion_matrix(labels_test, labels_pred, labels=labels, sample_weight=None)\n",
        "    labels= np.where(labels<1,\"R\",\"S\")\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "  return [score[1], report['FSc_R'][0], report['FSc_S'][0]]"
      ],
      "metadata": {
        "id": "YJJmoOq-o97t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing the evaluate() function \n",
        "Model_Report = evaluate(DL_AMX_GS_model,AMX_GS_test_array, AMX_Train_test_dic['labels_test'],AMX_GS_labels_pred)\n",
        "print(\"Results from Model for drug: AMX\")\n",
        "print(\"Using feature combination: GS\")\n",
        "print(\"Accuracy: \", Model_Report[0])\n",
        "print(\"R_f1_score: \", Model_Report[1])\n",
        "print(\"S_f1_score: \", Model_Report[2])"
      ],
      "metadata": {
        "id": "wMjJYgGIqboe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8) Use all functions and evaluate every drug in every feature combination!**"
      ],
      "metadata": {
        "id": "N5lGr0hoDCip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **a) Lets recall the list of drugs we have available and the combination of features we are interested in**"
      ],
      "metadata": {
        "id": "yExXAdaWZL4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check all drugs\n",
        "print(drug_list)\n",
        "\n",
        "# let's see all combinations we are interested in\n",
        "print(combo_list)"
      ],
      "metadata": {
        "id": "51wJM2XUaxtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **b) Create a loop that will go through all our functions using the lists above**"
      ],
      "metadata": {
        "id": "cZWO1rYocRQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets use all our functions this time and save our report into a single data structure\n",
        "DL_model_metrics = {}\n",
        "\n",
        "for drug in drug_list:\n",
        "  print(drug)\n",
        "  Drug_df = makeDF(drug) # creates one df per drug\n",
        "  Test_Train_dic = Split_train_test(Drug_df, drug) # splits each drug df into a dictionary with testing and training data\n",
        "  for combo in combo_list:\n",
        "    # Training each drug_combo features\n",
        "    labels_train = Test_Train_dic[\"labels_train\"]\n",
        "    features_train = combo_feat(Test_Train_dic[\"features_train\"], drug, combo) # create corresponding feature_df for training\n",
        "    DL_combo_model = run_DL(features_train, labels_train, drug, combo, sum = False) # runs deep learning model using the corresponding training feature_df \n",
        "    \n",
        "    # Predicting each drug_combo features\n",
        "    features_test = combo_feat(Test_Train_dic[\"features_test\"], drug, combo) # create corresponding feature_df for testing\n",
        "    labels_pred = predict(DL_combo_model, features_test) # generate predictions based on the feature combination tested\n",
        "\n",
        "    # Evaluating our models\n",
        "    labels_test = Test_Train_dic[\"labels_test\"]\n",
        "    report = evaluate(DL_combo_model,features_test, labels_test, labels_pred, cf=False)\n",
        "    DL_model_metrics[drug+\"_\"+combo] = report\n",
        "    \n",
        "    print(report)"
      ],
      "metadata": {
        "id": "glSAeIj2DrnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **b) Store the metrics report for all drugs and features combinations as a csv file**"
      ],
      "metadata": {
        "id": "m8CQMKARZ1zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dictionary into a dataframe\n",
        "DL_metrics = pd.DataFrame.from_dict(DL_model_metrics, orient='index',columns=[\"Accuracy\", \"R_f1_score\", \"S_f1_score\"]).reset_index()\n",
        "DL_metrics = DL_metrics.rename(columns = {'index':'Drug_combo'})\n",
        "\n",
        "# saving our metric results into a CSV file\n",
        "DL_metrics.to_csv(filepath+\"DL_metrics_df.csv\", index= False)\n",
        "DL_metrics\n"
      ],
      "metadata": {
        "id": "VmNdWS65fhRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **c) Create a bar graph showing accuracies of all drugs when using all features (G)**"
      ],
      "metadata": {
        "id": "2-6NzvrsbZaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering for all the rows that contain \n",
        "GS_filter = [drug_combo for drug_combo in DL_metrics['Drug_combo'] if drug_combo.endswith(\"GS\")]\n",
        "GS_df = DL_metrics.loc[DL_metrics[\"Drug_combo\"].isin(GS_filter)]\n"
      ],
      "metadata": {
        "id": "X408J96wZGD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting bar graph of only \n",
        "\n",
        "# Figure Size\n",
        "fig = plt.figure(figsize =(20, 8))\n",
        "\n",
        "# Adding title\n",
        "plt.title('Accuracy, R_f1_scores and S_f1_scores', fontsize = 12)\n",
        "\n",
        "# Variables to be plotted \n",
        "x = np.arange(len(GS_df[\"Drug_combo\"]))\n",
        "acc = list(GS_df[\"Accuracy\"])\n",
        "R_f1 = list(GS_df[\"R_f1_score\"])\n",
        "S_f1 = list(GS_df[\"S_f1_score\"])\n",
        "\n",
        "# Plotting barcharts\n",
        "acc_bar=plt.bar(x-0.25, height= acc, width=0.25, color=\"darkgrey\", edgecolor=\"gray\")\n",
        "rf1_bar=plt.bar(x, height= R_f1, width=0.25, color=\"steelblue\", align=\"center\", edgecolor=\"gray\")\n",
        "sf1_bar=plt.bar(x+0.25, height= S_f1, width=0.25, color=\"lightcyan\", edgecolor=\"gray\")\n",
        "\n",
        "plt.xticks([r for r in range(len(GS_df[\"Drug_combo\"]))],\n",
        "        GS_df[\"Drug_combo\"], fontsize = 12)\n",
        "\n",
        "#legend\n",
        "fig.legend([acc_bar,rf1_bar,sf1_bar],[\"Accuracy\", \"R_f1_score\", \"S_f1_score\"], bbox_to_anchor=(0.4,-0.35, 0.04, 0.4), fontsize=12)\n",
        "\n",
        "# Show Plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ShYKLLRNkkZz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}